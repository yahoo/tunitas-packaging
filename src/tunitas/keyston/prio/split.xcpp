// This is -*- c++ -*- nearly C++23 with Modules TS but in the S.C.O.L.D. stylings that are so popular these days.
// Copyright Yahoo Inc.
// Licensed under the terms of the Apache-2.0 license.
// For terms, see the LICENSE file at https://github.com/yahoo/tunitas-keyston/blob/master/LICENSE
// For terms, see the LICENSE file at https://git.tunitas.technology/all/components/keyston/tree/LICENSE
#divert <fpp>
namespace tunitas::keyston::prio {
  namespace package_split {
    namespace body::exported { }
    namespace interface = body::exported;
  }
  using namespace package_split::interface;
}
#import tunitas.keyston.measurement.Specimen
#import tunitas.keyston.measurement.Boundaries
#import tunitas.keyston.Shards
#import tunitas.keyston.octets.Variable
#include <hpp/tunitas.keyston.octets.Variable> // because Shards<Variable> requires the complete type
#import tunitas.keyston.prio.randomness_size
#import tunitas.view.Fixed
#include <hpp/tunitas.keyston.prio.randomness_size>
namespace tunitas::keyston::prio::package_split {
  using measurement::Specimen;
  using measurement::Boundaries;
  template<Size SIZE> using Nonce = view::Fixed<Octet, SIZE>;
  template<Size SIZE> using Randomness = view::Fixed<Octet, SIZE>;
  using Publick = octets::Variable;
  using Inputs = Shards<octets::Variable>;
  namespace body {
    enum Noshard { JOINT };
  }
  namespace usage { }
}
#endiv
#divert <hpp>
#import tunitas.Tuple
#import tunitas.array.Fixed
#import tunitas.view.Fixed
#import tunitas.keyston.measurement.Specimen
#import tunitas.keyston.prio.Name
#import tunitas.keyston.prio.required.Definition
#import tunitas.keyston.Shard
#import tunitas.keyston.Shards // for SHARDS_COUNT, being a global definitional constant
#import tunitas.keyston.quantity.Shards
namespace tunitas::keyston::prio::package_split {
  namespace body {
    namespace exported {
      //
      // Specification:
      //
      //   def measurement_to_input_shares(Prio3, measurement, nonce, rand):
      //   Vdaf.measurement_to_input_shares(measurement: Measurement, nonce: Bytes[Vdaf.NONCE_SIZE], rand: Bytes[Vdaf.RAND_SIZE]) -> tuple[Bytes, Vec[Bytes]]
      //
      // Upon completion of the split
      //
      //   <quote>
      //     Each Aggregator's input share contains its measurement share, proof share, and blind.
      //     The public share contains the Aggregators' joint randomness parts.
      //   </quote>
      //
      // Design:
      //
      //   Just what you see.
      //
      //   <quote ref=draft-irtf-cfrg-vdaf-06 ref="Section 7.2.1 Sharding">
      //     The algorithm is specified below.
      //     Notice that only one set of input and proof shares (called the "leader" shares below) are vectors of field elements.
      //     The other shares (called the "helper" shares) are represented instead by PRG seeds, which are expanded into vectors of field elements.
      //   </quote>
      //
      //   Actually this is tricky to get the template sense AND also the ability to infer the NONCE and RANDOMNESS sizes
      //   when the call site typically yses array::Fixed<...> but the formals here use span::Fixed<...>
      //   Can't easily get both template intference argumentimplicit AND conversion.
      //
      //   There really is no way around the ugliness of having to special-case HISTOGRAM is there?
      //
      // Usage:
      //
      //   You need a tutorial on calling a function?
      //   See Function<PRIO,NAME>::disassembly(...)
      //
      template<Name NAME, Size OF_NONCE, Size OF_RANDOMNESS> inline auto split(Specimen, Nonce<OF_NONCE> const &, Randomness<OF_RANDOMNESS> const &) -> Tuple<Publick, Inputs> requires (Name::HISTOGRAM != NAME);
      template<Name NAME, Size OF_NONCE, Size OF_RANDOMNESS> inline auto split(Specimen, Boundaries const &, Nonce<OF_NONCE> const &, Randomness<OF_RANDOMNESS> const &) -> Tuple<Publick, Inputs> requires (Name::HISTOGRAM == NAME);
    }
    template<required::Definition DEFINITION, Size OF_NONCE, Size OF_RANDOMNESS> auto continued(typename DEFINITION::Codec::Encoded const &, Nonce<OF_NONCE> const &, Randomness<OF_RANDOMNESS> const &) -> Tuple<Publick, Inputs>;
    //
    inline constexpr auto const NOBINDER = view::Fixed<Octet, 0uz>{};
    inline constexpr auto binder(Shard index) -> array::Fixed<Octet, 1uz>;
    inline constexpr auto binder(Noshard) -> array::Fixed<Octet, 1uz>;
    template<Size NONCE, Size ENCODED> inline constexpr auto binder(Shard, view::Fixed<Octet, NONCE>, view::Fixed<Octet, ENCODED>) -> array::Fixed<Octet, 1uz+NONCE+ENCODED>;
    template<Size NONCE, Size ENCODED> inline constexpr auto binder(Noshard, view::Fixed<Octet, NONCE>, view::Fixed<Octet, ENCODED>) -> array::Fixed<Octet, 1uz+NONCE+ENCODED>;
    // reminder: cannot do template argument inference and salso implicit conversion in the same step
    template<Size NONCE, Size ENCODED> inline constexpr auto binder(Shard s, view::Fixed<Octet, NONCE> n, array::Fixed<Octet, ENCODED> const &a) -> array::Fixed<Octet, 1uz+NONCE+ENCODED>   { return binder(s, n, static_cast<view::Fixed<Octet, ENCODED>>(a)); }
    template<Size NONCE, Size ENCODED> inline constexpr auto binder(Noshard s, view::Fixed<Octet, NONCE> n, array::Fixed<Octet, ENCODED> const &a) -> array::Fixed<Octet, 1uz+NONCE+ENCODED> { return binder(s, n, static_cast<view::Fixed<Octet, ENCODED>>(a)); }
  }
  namespace usage {
    template<typename DEFINITION, Name NAME, Size OF_NONCE, Size OF_RANDOMNESS> concept Arguments = requires(DEFINITION) {
      requires quantity::Shards{1u} < shards::SHARD_COUNT;
      requires OF_NONCE == DEFINITION::NONCE_SIZE.count();
      requires OF_RANDOMNESS == randomness_size(DEFINITION::Validity::JOINT_RANDOMNESS_LENGTH).count();
    };
  }
}
#endiv
#divert <ipp>
#import tunitas.keyston.octets.concatenate
#import tunitas.keyston.prio.Definition
namespace tunitas::keyston::prio::package_split {
  constexpr auto body::binder(Shard shard) -> array::Fixed<Octet, 1uz> { return array::Fixed<Octet, 1uz>{array::Fixed<Octet, 1uz>::Inplace{}, Octet(1u + underlying(shard))}; }
  constexpr auto body::binder(Noshard)     -> array::Fixed<Octet, 1uz> { return array::Fixed<Octet, 1uz>{array::Fixed<Octet, 1uz>::Inplace{}, Octet(0u)}; }
  template<Size NONCE, Size ENCODED> constexpr auto body::binder(Shard shard, view::Fixed<Octet, NONCE> nonce, view::Fixed<Octet, ENCODED> encoded) -> array::Fixed<Octet, 1uz+NONCE+ENCODED> { return octets::concatenate(binder(shard), nonce, encoded); }
  template<Size NONCE, Size ENCODED> constexpr auto body::binder(Noshard no, view::Fixed<Octet, NONCE> nonce, view::Fixed<Octet, ENCODED> encoded)  -> array::Fixed<Octet, 1uz+NONCE+ENCODED> { return octets::concatenate(binder(no), nonce, encoded); }
  //
  template<Name NAME, Size OF_NONCE, Size OF_RANDOMNESS> auto interface::split(Specimen specimen, Nonce<OF_NONCE> const &nonce, Randomness<OF_RANDOMNESS> const &randomness) -> Tuple<Publick, Inputs> requires (Name::HISTOGRAM != NAME) {
    using Definition = prio::Definition<NAME>;
    static_assert(usage::Arguments<Definition, NAME, OF_NONCE, OF_RANDOMNESS>);
    auto input = Definition::Codec::encode(specimen);
    return continued<Definition>(input, nonce, randomness);
  }
  template<Name NAME, Size OF_NONCE, Size OF_RANDOMNESS> auto interface::split(Specimen specimen, Boundaries const &boundaries, Nonce<OF_NONCE> const &nonce, Randomness<OF_RANDOMNESS> const &randomness) -> Tuple<Publick, Inputs> requires (Name::HISTOGRAM == NAME) {
    using Definition = prio::Definition<NAME>;
    static_assert(usage::Arguments<Definition, NAME, OF_NONCE, OF_RANDOMNESS>);
    auto input = Definition::Codec::encode(specimen, boundaries);
    return continued<Definition>(input, nonce, randomness);
  }
}
#endiv
#divert <tpp>
#import std.views.iota
#import tunitas.array.Variable
#import tunitas.keyston.exception.Unimplemented
#import tunitas.keyston.octets.Fixed
#import tunitas.keyston.prio.exception.Invariant
#import tunitas.keyston.prio.flp.dimension.cast // ... find this by ADL for flp dimensions -> Items or Bytes
#import tunitas.keyston.prio.split.Allocator
#import tunitas.keyston.prio.split.Slicer
#import tunitas.keyston.prio.Usage
#import tunitas.keyston.quantity.convert // .......... NOT finding this by ADL for Bytes -> Items
namespace tunitas::keyston::prio::package_split {
  template<required::Definition DEFINITION, Size OF_NONCE, Size OF_RANDOMNESS> auto body::continued(typename DEFINITION::Codec::Encoded const &input, Nonce<OF_NONCE> const &nonce, Randomness<OF_RANDOMNESS> const &randomness) -> Tuple<Publick, Inputs> {
    using Definition = DEFINITION;
    //
    // Split the random input into the various seeds.
    // SHARDS-1 for the helpers because the "leader" is a shard too
    constexpr auto const SHARDSM1 = shards::SHARD_COUNT.count() - 1u;
    using Allocated = array::Fixed<Octet, prg::SEED_SIZE.count()>;
    array::Fixed<Allocated, SHARDSM1> k_helper_input_shards{}, k_helper_proof_shards{}, k_helper_blind{};
    Allocated k_leader_blind{};
    Allocated k_prove{};
    {
      auto allocator = Allocator{randomness};
      if constexpr (Definition::use_joint_randomness()) {
        auto slicer = allocator.template slice<SHARDSM1, 3uz>();
        k_helper_input_shards = slicer.template stride<0uz>();
        k_helper_proof_shards = slicer.template stride<1uz>();
        k_helper_blind        = slicer.template stride<2uz>();
        k_leader_blind        = *allocator++;
      } else {
        auto slicer = allocator.template slice<SHARDSM1, 2uz>();
        k_helper_input_shards = slicer.template stride<0uz>();
        k_helper_proof_shards = slicer.template stride<1uz>();
        // k_helper_blind remains full of nulls
        // k_leader_blind remains full of null
      }
      k_prove = *allocator++;
      if (allocator) { throw exception::Invariant{"the randomness allocator should have been exhausted"}; }
    }
    //
    // Finish measurement shares and joint randomness parts.
    auto leader_input_shard = static_cast<typename Definition::Encoded::Input::Vector>(input);
    // [[FIXTHIS]] this does not need to be array::Variable.  We know the comlete allocation size.  It needs a cursor within a fixed allocation
    auto k_joint_randomness_parts = Shards<typename Definition::Amplifier::Seed::Storage>{};
    auto kjrp0 = k_joint_randomness_parts.begin();
    {
      auto kjrp = 1+kjrp0;
      for (auto shard : std::views::iota(Shard{}, Shard{SHARDSM1})) {
        auto helper_input_shard = Definition::Amplifier::template expand_as<typename Definition::Encoded::Input::Vector>(/*seed*/ k_helper_input_shards.at(underlying(shard)), Definition::Customizer::template domain_separation_tag<Usage::MEASUREMENT_SHARE>(), binder(shard));
        leader_input_shard -= helper_input_shard;
        if constexpr (Definition::use_joint_randomness()) {
          auto encoded = Definition::Encoded::Input::Definition::encode(helper_input_shard);
          auto part = Definition::Amplifier::derive_seed(k_helper_blind.at(underlying(shard)), Definition::Customizer::template domain_separation_tag<Usage::JOINT_RANDOMNESS_PART>(), binder(shard, nonce, encoded));
          *kjrp++ = move(part);
        }
      }
    }
    //
    // Finish joint randomness (maybe writing into the 0th position of k_joint_randomness_parts)
    auto joint_randomness = [&]() -> typename Definition::Encoded::Randomness::Joint {
      if constexpr (Definition::use_joint_randomness()) {
        auto encoded = Definition::Encoded::Input::Definition::encode(leader_input_shard);
        auto part = Definition::Amplifier::derive_seed(k_leader_blind, Definition::Customizer::template domain_separation_tag<Usage::JOINT_RANDOMNESS_PART>(), binder(JOINT, nonce, encoded));
        *kjrp0 = move(part);
        auto ret = typename Definition::Encoded::Randomness::Joint{};
        Definition::Amplifier::expand_into(ret, Definition::joint_randomness(k_joint_randomness_parts), Definition::Customizer::template domain_separation_tag<Usage::JOINT_RANDOMNESS>(), NOBINDER);
        return ret;
      } else {
        return {};
      }
    }();
    //
    // Finish the proof shares.
    auto leader_proof_shard = [&]() -> typename Definition::Encoded::Proof::Vector {
      auto prove_randomness = typename Definition::Encoded::Randomness::Prove{};
      Definition::Amplifier::expand_into(prove_randomness, /*seed*/ k_prove, Definition::Customizer::template domain_separation_tag<Usage::PROVE_RANDOMNESS>(), NOBINDER);
      auto leader_proof_shard = static_cast<typename Definition::Encoded::Proof::Vector>(Definition::Prover::prove(input, prove_randomness, joint_randomness));
      for (auto shard : std::views::iota(Shard{}, Shard{SHARDSM1})) {
        auto helper_proof_shard = Definition::Amplifier::template expand_as<typename Definition::Encoded::Proof::Vector>(k_helper_proof_shards.at(underlying(shard)), Definition::Customizer::template domain_separation_tag<Usage::PROOF_SHARE>(), binder(shard));
        leader_proof_shard -= helper_proof_shard;
      }
      return leader_proof_shard;
    }();
    //
    // Each Aggregator's input share contains its measurement share, proof share, and blind.
    // The public share contains the Aggregators' joint randomness parts.
    auto input_shards = [&]() -> Inputs {
      auto inputs = Inputs{};
      auto in = inputs.begin();
      *in++ = Definition::encode_leader_shard(leader_input_shard, leader_proof_shard, k_leader_blind);
      for (auto shard : std::views::iota(Shard{}, Shard{SHARDSM1})) {
        *in++ = Definition::encode_helper_shard(k_helper_input_shards.at(underlying(shard)), k_helper_proof_shards.at(underlying(shard)), k_helper_blind.at(underlying(shard)));
      }
      return inputs;
    }();
    auto public_shard = Definition::encode_public_shard(k_joint_randomness_parts);
    return {move(public_shard), move(input_shards)};
  }
}
#endiv
